{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56ce2e9-4162-4813-a385-06b0ce860504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "This notebook generate the sentiment analysis results and save it in UC for downstream use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5bed8d0-5605-4356-b14e-10446d12cfa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89a93f74-c7d7-4431-8e47-6231f66e92e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import textwrap\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from transformers import pipeline\n",
    "\n",
    "# Local application imports\n",
    "import de_utils as dut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f49c8dd0-d0a6-4315-8498-f05afe55004c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_spark = spark.sql(\"SELECT * FROM bupa_call_synthetic_dataset\")\n",
    "df = df_spark.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "190e9273-abdb-4cb2-b241-e25c2edfa1c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f758a1d5-e151-4f6d-82d8-74b083fccb49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "def summarize_sentiment(text, chunk_size=500):\n",
    "    # Break the text into chunks\n",
    "    chunks = textwrap.wrap(text, chunk_size)\n",
    "    \n",
    "    # Initialize variables to store scores\n",
    "    scores = []\n",
    "    first_chunk_score = None\n",
    "    last_chunk_score = None\n",
    "    \n",
    "    # Analyze each chunk\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        result = sentiment_analyzer(chunk)\n",
    "        score = result[0]['score']\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Capture scores for the first and last chunks\n",
    "        if i == 0:\n",
    "            first_chunk_score = score\n",
    "        if i == len(chunks) - 1:\n",
    "            last_chunk_score = score\n",
    "    \n",
    "    # Calculate the average score\n",
    "    average_score = sum(scores) / len(scores) if scores else 0.0\n",
    "    \n",
    "    return {\n",
    "        'average_score': average_score,\n",
    "        'first_chunk_score': first_chunk_score,\n",
    "        'last_chunk_score': last_chunk_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5040d22d-85e1-424e-b290-114524f1a8d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Implement the analysis \n",
    "sentiment_scores = df['Summary'].apply(summarize_sentiment)\n",
    "df[['average_score', 'first_chunk_score', 'last_chunk_score']] = pd.DataFrame(sentiment_scores.tolist(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e22aa5c8-f29b-45ee-af24-76dc9472be83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the data back to UC\n",
    "table_name = \"bupa_call_synthetic_dataset_with_sentiment_score\"\n",
    "dut.write_data_to_bricks_catalog(df, table_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1-sentiment-analysis.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
